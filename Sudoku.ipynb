{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Solving Sudoku with Feed-Forward Neural Networks\n","### By: Mohamed Abdelhamid Ghanem -- 70026144"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Imports and Dependencies:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Dataset Loading & Preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","sudoku_df = pd.read_csv(\"sudoku.csv\")\n","sudoku_records = sudoku_df.to_dict('records')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["sudoku_records = sudoku_records[:10000]"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([9, 9])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import random\n","\n","random.seed(2022)\n","\n","class SudokuDataset(Dataset):\n","    def __init__(self, training=True, augment_prob=0.5, split_ratio=0.8, device=\"cuda\") -> None:\n","        super().__init__()\n","        self.training = training\n","        self.augment_prob = augment_prob\n","        self.device = device\n","        train_size = int(len(sudoku_records)*split_ratio)\n","        if training:\n","            self.puzzles = sudoku_records[:train_size]\n","        else:\n","            self.puzzles = sudoku_records[train_size:]\n","    \n","    def empty_randomly(self, arr):\n","        empty_count = random.randint(0, 32)\n","        indices = np.arange(empty_count)\n","        random.shuffle(indices)\n","        arr[indices] = 0\n","        return arr\n","    \n","    def __len__(self):\n","        return len(self.puzzles)\n","    \n","    def __getitem__(self, index):\n","        if random.random() < self.augment_prob:\n","            puzzle = np.array([int(x) for x in self.puzzles[index][\"solution\"]])\n","            puzzle = self.empty_randomly(puzzle)\n","        else:\n","            puzzle = np.array([int(x) for x in self.puzzles[index][\"puzzle\"]])\n","        puzzle = puzzle.reshape((9,9))\n","\n","        solution = np.array([int(x) for x in self.puzzles[index][\"solution\"]])\n","        solution = solution.reshape((9,9))\n","\n","        # Convert to tensor and one-hot encode puzzle\n","        puzzle = torch.tensor(puzzle).to(self.device)\n","        puzzle_1h = F.one_hot(puzzle, 10).permute(2, 0, 1).float()\n","        solution = torch.tensor(solution).to(self.device)\n","\n","        return puzzle, puzzle_1h, solution\n","\n","a, b, c = SudokuDataset(device=\"cpu\").__getitem__(5)\n","a.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Model Definition\n","For this task, we use the famous UNet convolutional architecture. It's essentially an encoder-decoder architecture that generates the output class map by downsampling then upsampling the input map. "]},{"cell_type":"markdown","metadata":{},"source":["#### 3.1 Building Blocks\n","The model is built out of convolutional ReLU-activated upsampling and downsampling blocks."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class DoubleConv(nn.Module):\n","    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # if bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # if you have padding issues, see\n","        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n","        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.2 Model Architecture\n","In addition to encoder/decoder blocks, the architecture uses skip connections to retain spatial information lost in downsampling."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","        factor = 2 if bilinear else 1\n","\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512 // factor)\n","        self.up1 = Up(512, 256 // factor, bilinear)\n","        self.up2 = Up(256, 128 // factor, bilinear)\n","        self.up3 = Up(128, 64 // factor, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x = self.up1(x4, x3)\n","        x = self.up2(x, x2)\n","        x = self.up3(x, x1)\n","        logits = self.outc(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Model Training"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 19/2000 [00:00<00:10, 181.20it/s]"]},{"name":"stdout","output_type":"stream","text":["Evaluating model..\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2000/2000 [00:09<00:00, 219.22it/s]\n","  0%|          | 1/2000 [00:00<03:37,  9.19it/s]"]},{"name":"stdout","output_type":"stream","text":["0.015\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2000/2000 [02:48<00:00, 11.85it/s]\n","  1%|          | 23/2000 [00:00<00:08, 222.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Evaluating model..\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2000/2000 [00:09<00:00, 219.23it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch #0 validation accuracy= 2.35%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from torch.optim import Adam\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","class Trainer():\n","    def __init__(self, batch_size, device=\"cuda\"):\n","        self.model = UNet(n_channels=10, n_classes=9).to(device)\n","        self.batch_size = batch_size\n","        self.train_dataset = SudokuDataset(training=True, device=device)\n","        self.train_dataloader = DataLoader(self.train_dataset, batch_size=batch_size)\n","\n","        self.val_dataset = SudokuDataset(training=False, device=device)\n","        self.val_dataloader = DataLoader(self.val_dataset, batch_size=1)\n","\n","        self.optimizer = Adam(self.model.parameters(), lr=7e-4)\n","        self.loss_fn = nn.CrossEntropyLoss()\n","    \n","    def train(self, n_epochs):\n","        best_accr = 0.0\n","        self.model.train()\n","        for epoch in range(n_epochs):\n","            for puzzle, puzzle_1h, sol_true in tqdm(self.train_dataloader, total=len(self.train_dataloader)):\n","                self.optimizer.zero_grad()\n","                sol_logits = self.model(puzzle_1h)\n","                # sol_pred = sol_logits.max(1)[1]\n","                loss = self.loss_fn(sol_logits, sol_true-1)\n","                loss.backward()\n","                self.optimizer.step()\n","            val_accr = self.evaluate()\n","            print(f\"Epoch #{epoch} validation accuracy= {val_accr*100:.2f}%\")\n","            if val_accr > best_accr:\n","                best_accr = val_accr\n","\n","    def evaluate(self):\n","        correct = 0\n","        self.model.eval()\n","        print(f\"Evaluating model..\")\n","        for puzzle, puzzle_1h, sol_true in tqdm(self.val_dataloader, total=len(self.val_dataloader)):\n","            sol_logits = self.model(puzzle_1h)\n","            sol_pred = sol_logits.max(1)[1]+1\n","            correct += torch.all(sol_pred[puzzle==0] == sol_true[puzzle==0]).item()\n","        accr = correct/len(self.val_dataloader)\n","        return accr\n","\n","\n","\n","\n","trainer = Trainer(4, device=\"cpu\")\n","print(trainer.evaluate())\n","trainer.train(1)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["7200000"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(trainer.train_dataset.puzzles)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('MattingEnv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"919ac87e097a676ea32bf155850d8ba412ce6cb4721b3b75e12ac9ec60aca34f"}}},"nbformat":4,"nbformat_minor":2}
