{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Solving Sudoku with Feed-Forward Neural Networks\n","### By: Mohamed Abdelhamid Ghanem -- 70026144"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Global Imports and Dependencies:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Dataset Loading & Preprocessing\n","\n","**Note**: Before you proceed, you need to download the Sudoku 9M dataset from Kaggle and place he `sudoku.csv` file it in the same directory as this notebook."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","sudoku_df = pd.read_csv(\"sudoku.csv\")\n","sudoku_records = sudoku_df.to_dict('records')"]},{"cell_type":"markdown","metadata":{},"source":["In our dataloader, we employ a trick to augment training by taking puzzle solutions and emptying random cells then pass them to the model."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import random\n","\n","random.seed(2022)\n","\n","class SudokuDataset(Dataset):\n","    def __init__(self, training=True, augment_prob=0.5, split_ratio=0.8, device=\"cuda\") -> None:\n","        super().__init__()\n","        self.training = training\n","        self.augment_prob = augment_prob\n","        self.device = device\n","        train_size = int(len(sudoku_records)*split_ratio)\n","        if training:\n","            self.puzzles = sudoku_records[:train_size]\n","        else:\n","            self.puzzles = sudoku_records[train_size:]\n","    \n","    def empty_randomly(self, arr):\n","        empty_count = random.randint(1, 43)\n","        indices = random.sample(range(9*9), empty_count)\n","        arr[indices] = 0\n","        return arr\n","    \n","    def __len__(self):\n","        return len(self.puzzles)\n","    \n","    def __getitem__(self, index):\n","        if self.training and random.random() < self.augment_prob:\n","            puzzle = np.array([int(x) for x in self.puzzles[index][\"solution\"]])\n","            puzzle = self.empty_randomly(puzzle)\n","        else:\n","            puzzle = np.array([int(x) for x in self.puzzles[index][\"puzzle\"]])\n","        puzzle = puzzle.reshape((9,9))\n","\n","        solution = np.array([int(x) for x in self.puzzles[index][\"solution\"]])\n","        solution = solution.reshape((9,9))\n","\n","        # Convert to tensor and one-hot encode puzzle\n","        puzzle = torch.tensor(puzzle).to(self.device)\n","        puzzle_1h = F.one_hot(puzzle, 10).permute(2, 0, 1).float()\n","        solution = torch.tensor(solution).to(self.device)\n","\n","        return puzzle, puzzle_1h, solution\n","\n","# a, b, c = SudokuDataset(device=\"cpu\").__getitem__(5)\n","# a.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Model Definition\n","For this task, we use the famous UNet convolutional architecture. It's essentially an encoder-decoder architecture that generates the output class map by downsampling then upsampling the input map. "]},{"cell_type":"markdown","metadata":{},"source":["#### 3.1 Building Blocks\n","The model is built out of convolutional ReLU-activated upsampling and downsampling blocks."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class DoubleConv(nn.Module):\n","    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # if bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # if you have padding issues, see\n","        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n","        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n","\n","\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.2 Model Architecture\n","In addition to encoder/decoder blocks, the architecture uses skip connections to retain spatial information lost in downsampling."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, n_channels, n_classes, bilinear=False):\n","        super(UNet, self).__init__()\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.bilinear = bilinear\n","        factor = 2 if bilinear else 1\n","\n","        self.inc = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512 // factor)\n","        self.up1 = Up(512, 256 // factor, bilinear)\n","        self.up2 = Up(256, 128 // factor, bilinear)\n","        self.up3 = Up(128, 64 // factor, bilinear)\n","        self.outc = OutConv(64, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x = self.up1(x4, x3)\n","        x = self.up2(x, x2)\n","        x = self.up3(x, x1)\n","        logits = self.outc(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Model Training"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from torch.optim import Adam\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","class Trainer():\n","    def __init__(self, batch_size, model_path=None, augment_prob=0.5, device=\"cuda\"):\n","        self.model = UNet(n_channels=10, n_classes=9).to(device)\n","        if model_path:\n","            self.model.load_state_dict(torch.load(model_path))\n","        self.batch_size = batch_size\n","        self.train_dataset = SudokuDataset(training=True, augment_prob=augment_prob, device=device)\n","        self.train_dataloader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n","\n","        self.val_dataset = SudokuDataset(training=False, device=device)\n","        self.val_dataloader = DataLoader(self.val_dataset, batch_size=512)\n","\n","        self.optimizer = Adam(self.model.parameters(), lr=7e-4)\n","        self.loss_fn = nn.CrossEntropyLoss()\n","    \n","    def train(self, n_epochs, start_epoch=0, early_stop=True):\n","        best_accr = 0.0\n","        for epoch in range(start_epoch, n_epochs):\n","            self.model.train()\n","            for puzzle, puzzle_1h, sol_true in tqdm(self.train_dataloader, total=len(self.train_dataloader)):\n","                self.optimizer.zero_grad()\n","                sol_logits = self.model(puzzle_1h)\n","                loss = self.loss_fn(sol_logits, sol_true-1)\n","                loss.backward()\n","                self.optimizer.step()\n","            torch.save(self.model.state_dict(), f\"pretrained/unet_sudoku_epoch_{epoch}.pth\")\n","            val_accr = self.evaluate()\n","            print(f\"Epoch #{epoch} validation accuracy= {val_accr*100:.2f}%\")\n","            if val_accr > best_accr:\n","                best_accr = val_accr\n","                torch.save(self.model.state_dict(), \"pretrained/unet_sudoku_best_model.pth\")\n","            elif early_stop:\n","                return\n","\n","\n","    def evaluate(self):\n","        correct = 0\n","        self.model.eval()\n","        print(f\"Evaluating model..\")\n","        for puzzle, puzzle_1h, sol_true in tqdm(self.val_dataloader, total=len(self.val_dataloader)):\n","            sol_logits = self.model(puzzle_1h)\n","            sol_pred = sol_logits.max(1)[1]+1\n","            for i in range(sol_pred.shape[0]):\n","                correct += torch.all(sol_pred[i, puzzle[i]==0] == sol_true[i, puzzle[i]==0]).item()\n","        accr = correct/(len(self.val_dataloader)*self.val_dataloader.batch_size)\n","        return accr\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["**Note**: in case you want to start training from a pretrained checkpoint, you can provide the `model_path` argument to `Trainer`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer = Trainer(64, \"pretrained/unet_sudoku_epoch_0.pth\", augment_prob=0.2, device=\"cuda\")\n","trainer.train(10, start_epoch=1)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Performance\n","The UNet model scores a best validation accuracy of %. Note that this represents the ratio of puzzles that were fuly solved correctly, not the percentage of digits correctly placed. The latter, of course, would be higher than the former."]},{"cell_type":"markdown","metadata":{},"source":["## Acknowledgments\n","The UNet PyTorch implementation used here was adapted from `milesial`'s [Pytorch-UNet repository](https://github.com/milesial/Pytorch-UNet)."]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('MattingEnv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"919ac87e097a676ea32bf155850d8ba412ce6cb4721b3b75e12ac9ec60aca34f"}}},"nbformat":4,"nbformat_minor":2}
